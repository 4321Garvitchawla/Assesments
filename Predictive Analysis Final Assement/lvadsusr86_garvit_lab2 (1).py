# -*- coding: utf-8 -*-
"""Lvadsusr86_garvit_lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_4MO8Nvdxmb6WY4lXmtl8XvUkxeFS88h
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch4-Assessment/main/auto-mpg.csv')

df

# Data Preprocessing
# Replace '?' with NaN in 'horsepower' column
df['horsepower'] = df['horsepower'].replace('?', pd.NA)
# Convert 'horsepower' column to numeric
df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')

missing_value=df.isnull().sum()
print("The missing values in the data set are:",missing_value)

filling_values=df.fillna(df.mean(), inplace=True)
print("Fillng the missing value:",filling_values)

missing_value=df.isnull().sum()
print("The missing values in the data set are:",missing_value)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features")
plt.xticks(rotation=45)
plt.show()

# handling outliers using IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

def remove_outliers(df):
    return df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

# removing outliers from the dataset
df = remove_outliers(df)

#now check using the boxplot

sns.boxplot(df)

# Descriptive statistics
print(df.describe())

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

df.corr()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


X = df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration','model year','origin']]
y = df['mpg']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)
print("Mean Squared Error:", mse)
print("Root Mean Squared Error:", rmse)
print("R-squared Score:", r2)

