# -*- coding: utf-8 -*-
"""Lvadsusr86_garvit_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iMzpWWYHYpfcdZ5JJtN0RDjk_97I8Eda
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch4-Assessment/main/loan_approval.csv')

df

missing_value=df.isnull().sum()
print("The missing values in the data set are:",missing_value)

filling_values=df.fillna(df.mean(), inplace=True)
print("Fillng the missing value:",filling_values)

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features")
plt.xticks(rotation=45)
plt.show()

#removing the outliers
Q1 = df.quantile(0.35)
Q3 = df.quantile(0.65)
IQR = Q3 - Q1

df_no_outliers = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]

#checking boxplot after removing outliers
plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of Numerical Features")
plt.xticks(rotation=45)
plt.show()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

df[' education'] = label_encoder.fit_transform(df[' education'])
df[' self_employed'] = label_encoder.fit_transform(df[' self_employed'])
df[' loan_status'] = label_encoder.fit_transform(df[' loan_status'])

print("Encoded education categories:", label_encoder.classes_)
print("Encoded loan_status categories:", label_encoder.classes_)
print("Encoded self_employeed categories:", label_encoder.classes_)

df

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

df.corr()

X = df.drop(columns=['loan_id', ' loan_status'])
y = df[' loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report

y_pred = rf_classifier.predict(X_test)

algos = ['Decision tree','Logistic','RandomForest', 'XGB']
accs=[]

dec_clf = DecisionTreeClassifier()
dec_clf.fit(X_train,y_train)
y_pred = dec_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Decision tree Accuracy:", accuracy)
print(classification_report(y_test, y_pred))
accs.append(round(accuracy*100,2))


lr_clf = LogisticRegression()
lr_clf.fit(X_train,y_train)
y_pred = lr_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Logistic tree Accuracy:", accuracy)
print(classification_report(y_test, y_pred))
accs.append(round(accuracy*100,2))


RF_clf = RandomForestClassifier()
RF_clf.fit(X_train,y_train)
y_pred = RF_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("RandomForest  Accuracy:", accuracy)
print(classification_report(y_test, y_pred))
accs.append(round(accuracy*100,2))


xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
xgb_clf.fit(X_train, y_train)
y_pred = xgb_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("XGB Accuracy:", accuracy)
print(classification_report(y_test, y_pred))
accs.append(round(accuracy*100,2))

accs

print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))