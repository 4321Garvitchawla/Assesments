# -*- coding: utf-8 -*-
"""LVADSUSR86_Garvit_lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uezxEL-JqS4iZgcUq-cvlb5raOAgPbxq
"""

import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch4-Assessment/main/booking.csv')

df

df.describe()

df['booking status'].unique()

df.isnull().sum()

filling_values=df.fillna(df.mean(), inplace=True)

Dropping_value = df.dropna()
print("Dropping the values:",Dropping_value)
duplicate = df.duplicated().sum()
print("Number of duplicate entries:", duplicate)
Drop_Duplicate = df.drop_duplicates()
print("Dropped off all the duplicate values",Drop_Duplicate)

df.describe()

fig = plt.figure(figsize =(10, 7))
data = df[['number of adults',	'number of children','number of weekend nights','number of week nights','number of week nights','average price']]
sns.boxplot(data)

def cap_data(df):
    for col in df.columns:
        print("capping the ",col)
        if (((df[col].dtype)=='float64') | ((df[col].dtype)=='int64')):
            percentiles = df[col].quantile([0.03,0.95]).values
            df[col][df[col] <= percentiles[0]] = percentiles[0]
            df[col][df[col] >= percentiles[1]] = percentiles[1]
        else:
            df[col]=df[col]
    return df

df=cap_data(df)

fig = plt.figure(figsize =(10, 7))
data = df[['number of adults',	'number of children','number of weekend nights','number of week nights','number of week nights','average price']]
sns.boxplot(data)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()

df['room type'] = label_encoder.fit_transform(df['room type'])
df['type of meal'] = label_encoder.fit_transform(df['type of meal'])
df['booking status'] = label_encoder.fit_transform(df['booking status'])

print("Encoded room type categories:", label_encoder.classes_)
print("Encoded meal type categories:", label_encoder.classes_)
print("Encoded booking status categories:", label_encoder.classes_)

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

df.drop(columns = ['number of children','repeated','P-C','P-not-C'],axis=1,inplace=True)

df.drop(columns = ['Booking_ID'],axis=1,inplace=True)

df.head()

df.describe()

from sklearn.model_selection import train_test_split
X = df.drop(columns=['booking status','market segment type'])
y = df['booking status']

from sklearn.preprocessing import StandardScaler
st_X= StandardScaler()
X_train= st_X.fit_transform(X_train)
X_test= st_X.transform(X_test)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=10)

"""Sigmoid Function: The Sigmoid function, also known as the logistic function, is a mathematical functions that maps any real-valued number to a value between 0 and 1.

Role in Logistic Regressions: In Logistic Regression, the goal is to predict the probability that a given input belongs to a certain class (e.g., whether a booking is confirmed or not confirming both). However, linear regression models can't output probabilities directly because they can produce values outside the range of [0, 1].


> Add blockquote


"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=0, criterion='entropy')

from sklearn.metrics import accuracy_score

predictions_test=clf.predict(X_test)
accuracy_score(y_test, predictions_test)

y_pred= clf.predict(X_test)

from sklearn.metrics import confusion_matrix
cm= confusion_matrix(y_test, y_pred)
cm

from sklearn.linear_model import LogisticRegression
classifier= LogisticRegression(random_state=0)
classifier.fit(X_train, y_train)

y_pred= classifier.predict(X_test)

y_pred=classifier.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.metrics import mean_absolute_error,mean_squared_error

mse = mean_squared_error(y_test,y_pred)
mae = mean_absolute_error(y_test,y_pred)
rmse = np.sqrt(mse)
print(mse)
print(mae)
print(rmse)